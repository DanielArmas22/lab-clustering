{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575b5de1",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "In this section, we will import the necessary libraries for clustering and visualization, including pandas, numpy, matplotlib, seaborn, and sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b9a00",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset\n",
    "In this section, we will load the dataset.csv file, display the first few rows, and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "# Select relevant features for clustering\n",
    "features = ['IngresosAnuales (k$)', 'ScoreGasto (1-100)']\n",
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffef12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of features\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.histplot(X[:, i], kde=True, bins=20)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a04abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inertia for different numbers of clusters\n",
    "inertia = []\n",
    "for n in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method to Determine Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans with the optimal number of clusters (e.g., 5)\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77060068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=100, cmap='viridis', label='Data Points')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', label='Centroids')\n",
    "plt.xlabel('Ingresos Anuales (k$)')\n",
    "plt.ylabel('Score de Gasto (1-100)')\n",
    "plt.title('Clusters and Centroids')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the dataset\n",
    "df['Cluster'] = labels\n",
    "# Display the updated dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1772723",
   "metadata": {},
   "source": [
    "# Assign Clusters to Data\n",
    "In this section, we will add the cluster labels as a new column in the dataset and display the updated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769df2f",
   "metadata": {},
   "source": [
    "# Visualize Clusters\n",
    "In this section, we will plot the clusters along with their centroids using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d83a1a",
   "metadata": {},
   "source": [
    "# Apply KMeans Clustering\n",
    "In this section, we will apply the KMeans algorithm with the optimal number of clusters and fit it to the selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7858e21",
   "metadata": {},
   "source": [
    "# Determine Optimal Number of Clusters\n",
    "In this section, we will use the elbow method to calculate inertia for different numbers of clusters and plot the results to determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1cf00",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "In this section, we will visualize the distribution of selected features using seaborn and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51fc90",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "In this section, we will handle missing values and select relevant features for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7619e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
